{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import itertools\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global Community\n",
    "global train_n\n",
    "global neq\n",
    "global nex\n",
    "global nall\n",
    "train_n=40\n",
    "Community=np.ndarray.tolist(np.zeros(train_n+1))\n",
    "\n",
    "\n",
    "#The time series are read in from their corresponding .txt files.\n",
    "exfiles=os.listdir('./EXPLOSIONS')\n",
    "eqfiles=os.listdir('./EARTHQUAKES')\n",
    "nex=len(exfiles)\n",
    "neq=len(eqfiles)\n",
    "def dist2(e1,e2):\n",
    "    minn=500\n",
    "    maxx=750\n",
    "    div=maxx-minn\n",
    "    diststemp=[]\n",
    "    for delay in range(500):\n",
    "        cross=0\n",
    "        \n",
    "        \n",
    "        for i in range(minn,maxx):\n",
    "            if (e1[i]-e2[i+delay])*(e1[i+1]-e2[i+1+delay])<=0:\n",
    "                cross=cross+1\n",
    "        diststemp.append(cross)\n",
    "    return (1-np.max(diststemp)/div)/(np.max(diststemp)/div)\n",
    "    \n",
    "\n",
    "EQ=[]\n",
    "for i in eqfiles:\n",
    "    eqtemp=[]\n",
    "    with open('./EARTHQUAKES/'+i) as f:\n",
    "        for line in f.readlines():\n",
    "            if line==\"\\n\":\n",
    "                pass\n",
    "            else:\n",
    "                eqtemp.append(float(line))\n",
    "    EQ.append(eqtemp)\n",
    "EX=[]\n",
    "for i in exfiles:\n",
    "    extemp=[]\n",
    "    with open('./EXPLOSIONS/'+i) as f:\n",
    "        for line in f.readlines():\n",
    "            if line==\"\\n\":\n",
    "                pass\n",
    "            else:\n",
    "                extemp.append(float(line))\n",
    "    EX.append(extemp)\n",
    "\n",
    "\n",
    "#The earthquakes and explosions are normalized.\n",
    "EQnorm=[]\n",
    "for e in EQ:\n",
    "    mean=np.mean(e)\n",
    "    std=np.var(e)**.5\n",
    "    etemp=[]\n",
    "    for i in range(len(e)):\n",
    "        etemp.append((e[i]-mean)/std)\n",
    "    \n",
    "    EQnorm.append(etemp)\n",
    "\n",
    "\n",
    "EXnorm=[]\n",
    "for e in EX:\n",
    "    mean=np.mean(e)\n",
    "    std=np.var(e)**.5\n",
    "    etemp=[]\n",
    "    for i in range(len(e)):\n",
    "        etemp.append((e[i]-mean)/std)\n",
    "    \n",
    "    EXnorm.append(etemp)\n",
    "\n",
    "\n",
    "#The data is balanced and distance matrix is calculated.\n",
    "EX=sample(EX,neq)\n",
    "EXnorm=sample(EXnorm,neq)\n",
    "EQXnorm=EQnorm+EXnorm\n",
    "EQX=EQ+EX\n",
    "\n",
    "nall=2*neq\n",
    "Dskew=np.zeros((nall,nall))\n",
    "\n",
    "for i in range(nall):\n",
    "    for j in range(i+1,nall):\n",
    "        Dskew[i][j]=(dist2(EQX[i],EQX[j]))\n",
    "\n",
    "\n",
    "Dall=np.transpose(Dskew)+Dskew\n",
    "\n",
    "#PaLD was released as an R package after I wrote this notebook. Here, I'm saving the distance matrix and reading it into an R script to get the R pald output.\n",
    "print(*[np.round(x[i],2) for i in range(nall) for x in [x for x in Dall]],file=open(\"./dall.csv\",'w'))\n",
    "subprocess.call(\"Rscript.exe C:\\Mmbah54\\Mmbah54\\Works\\Math\\Research\\earthquake\\Pythonstuff\\pald.R\", shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell was used to get all the .txt files into a standard form.\n",
    "\n",
    "\"\"\" exfiles=os.listdir('./Nevada1/EXPLOSIONS')\n",
    "eqfiles=os.listdir('./Nevada1/EARTHQUAKES')\n",
    "\n",
    "\n",
    "for i in exfiles:\n",
    "    newfile=\"\"\n",
    "    with open('./Nevada1/EXPLOSIONS/'+i) as f:\n",
    "        for line in f.readlines():\n",
    "            newfile=newfile+line[16:]\n",
    "\n",
    "    print(newfile,file=open(\"./Nevada1/EXPLOSIONS/exreform\"+str(i),'w')) \n",
    "\n",
    "for i in eqfiles:\n",
    "    newfile=\"\"\n",
    "    with open('./Nevada1/EARTHQUAKES/'+i) as f:\n",
    "        for line in f.readlines():\n",
    "            newfile=newfile+line[16:]\n",
    "\n",
    "    print(newfile,file=open(\"./Nevada1/EARTHQUAKES/eqreform\"+str(i),'w')) \n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionfromD(Dall,reps=100):\n",
    "    global Community\n",
    "    Confuse=[[0,0],[0,0]]\n",
    "    for dum in range(reps):\n",
    "        \n",
    "        #Monte Carlo cross-validation\n",
    "        ind=sample(range(neq),k=int(train_n/2))+sample(range(neq,nall),int(train_n/2))\n",
    "\n",
    "        test=sample([x for x in range(nall) if not (x in ind )],1)[0]\n",
    "        D=[[Dall[i][j] for j in ind+[test]] for i in ind+[test]]\n",
    "\n",
    "\n",
    "        #PaLD algorithm\n",
    "        U=np.zeros((train_n+1,train_n+1))\n",
    "        U=np.ndarray.tolist(U)\n",
    "        for x in range(train_n+1):\n",
    "            for y in range(train_n+1):\n",
    "                U[x][y]=[ z for z in range(train_n+1) if D[z][x]<=D[y][x] or D[z][y]<=D[x][y]]\n",
    "\n",
    "        C=np.ndarray.tolist(np.zeros((train_n+1,train_n+1)))\n",
    "        for x in range(train_n+1):\n",
    "            for w in range(train_n+1):\n",
    "                C[x][w]=np.sum([ float(int(D[z][x]<D[z][y] and z==w))/(train_n)/len(U[x][y])   for [y,z] in itertools.product(range(train_n+1),range(train_n+1)) if (y!=x and z in U[x][y])   ])\n",
    "\t    \n",
    "        \n",
    "        stronk=np.mean([C[i][i] for i in range(train_n+1)])/2\n",
    "\n",
    "        Community=np.ndarray.tolist(np.zeros(train_n+1))\n",
    "        for x in range(train_n+1):\n",
    "            Community[x]=[z for z in range(train_n+1) if min(C[x][z],C[z][x])>stronk]\n",
    "\n",
    "        partitions=[]\n",
    "        for i in range(train_n+1):\n",
    "            pot=partition([i])\n",
    "            if not pot in partitions:\n",
    "                partitions.append(pot)\n",
    "        maxlen=np.max([len(pot) for pot in partitions])\n",
    "        testpart=partition([train_n])\n",
    "\n",
    "        #Making the confusion matrix -- If the event is in the largest partition, I classify it as an earthquake. Generally, the explosions are more spread out and separated.\n",
    "        if len(testpart)==maxlen:\n",
    "            if test>=neq:\n",
    "                Confuse[0][1]=Confuse[0][1]+1\n",
    "                #print(test+1)\n",
    "            else: \n",
    "                Confuse[0][0]=Confuse[0][0]+1\n",
    "                \n",
    "        else: \n",
    "            if test<neq:\n",
    "                Confuse[1][0]=Confuse[1][0]+1\n",
    "                #print(-test-1)\n",
    "            else:\n",
    "                Confuse[1][1]=Confuse[1][1]+1\n",
    "    print(Confuse)\n",
    "\n",
    "\n",
    "\n",
    "#Recursive function to find the partition of each event.\n",
    "def partition(li):\n",
    "\t\t\tli1=set(li)\n",
    "\t\t\tli=set(li)\n",
    "\t\t\tfor x in li:\n",
    "\t\t\t\tfor i in range(train_n+1):\n",
    "\t\t\t\t\tif x in Community[i]:\n",
    "\t\t\t\t\t\tli=li.union(set(Community[i]))\n",
    "\t\t\tif li1==li:    \n",
    "\t\t\t\treturn li\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn partition(li)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[481, 79], [26, 414]]\n"
     ]
    }
   ],
   "source": [
    "train_n=30\n",
    "confusionfromD(Dall,reps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[513, 75], [3, 409]]\n"
     ]
    }
   ],
   "source": [
    "train_n=30\n",
    "confusionfromD(Dall,reps=1000)\n",
    "#Not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "169987767c228537e4e2c35dd6f18e194f856f259cc3084cc52b214c9fc40b07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
